{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebooks and CONSTELLATION\n",
    "\n",
    "This notebook is an introduction to using Jupyter notebooks with CONSTELLATION. In part 1, we'll learn how to send data to CONSTELLATION to create and modify graphs. In part 2, we'll learn how to retrieve graph data from CONSTELLATION. Part 3 will be about getting and setting information about the graph itself. Part 4 will show how to call plugins. Part 5 is a quick look at types. Part 6 will be fun (and occasionally useful). Part 7 introduces some advanced graph usage.\n",
    "\n",
    "This notebook uses Python libraries that are included in the [Python Anaconda3 distribution](https://www.anaconda.com/distribution/) version 2020.02, Python v3.7.6.\n",
    "\n",
    "To run through the notebook, click on the triangular 'run cell' button in the toolbar to execute the current cell and move to the next cell.\n",
    "\n",
    "Let's start by seeing if we can talk to CONSTELLATION. Make sure that CONSTELLATION is running, and you've started the external scripting server (which has been done for you if you started the Jupyter notebook server from CONSTELLATION). The external scripting server makes a REST HTTP API available for use by any HTTP client.\n",
    "\n",
    "The Python ``import`` statement looks for a library with the given name. Click the 'run cell' button to execute it.\n",
    "\n",
    "(All of the libraries used here are included in the Anaconda Python distribution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL.Image, PIL.ImageDraw, PIL.ImageFilter, PIL.ImageFont\n",
    "\n",
    "# Also import some of the notebook display methods so we can display nice things.\n",
    "#\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "# This is a convenient Python interface to the REST API.\n",
    "#\n",
    "import constellation_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = constellation_client.Constellation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the external scripting server started, it automatically installed the ``constellation_client`` package with pip install. This is a custom python package included in Constellation. It's also important that you create a client instance **after** you start the REST server, because the server creates a secret that the client needs to know to communicate with the server.\n",
    "\n",
    "After the import succeeds, we then create a Python object that communicates with CONSTELLATION on our behalf. CONSTELLATION provides communication with the outside world using HTTP (as if it were a web server) and JSON (a common data format). The ``constellation_client`` library hides these details so you can just use Python.\n",
    "\n",
    "# IMPORTANT\n",
    "If the \"REST Directory\" has been changed in Constellation's options, you must run the following to point constellation_client to the new folder for the \"REST Directory\". Be sure to replace `C:\\Path\\To\\Directory\\` with the actual filepath of the directory or the actual file itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.update_rest(r\"C:\\Path\\To\\Directory\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sending Data to CONSTELLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically you'll have some data in a CSV file. We'll use some Python tricks (in this case, ``io.StringIO``) to make it look like we have a separate CSV file that we're reading into a dataframe. (If your data is in an Excel spreadsheet, you could use ``read_excel()`` to read it it directly, rather than saving it to a CVS file first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = '''\n",
    "from_address,from_country,to_address,to_country,dtg\n",
    "abc@example1.com,Brazil,def@example2.com,India,2017-01-01 12:34:56\n",
    "abc@example1.com,Brazil,ghi@example3.com,Zambia,2017-01-01 14:30:00\n",
    "jkl@example4.com,India\n",
    "'''.strip()\n",
    "df = pd.read_csv(io.StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting our data in a dataframe is a good idea; not only can we easily manipulate it, but it's easy to send a dataframe to CONSTELLATION, as long as we tell CONSTELLATION what data belongs where.\n",
    "\n",
    "A dataframe is a table of data, but CONSTELLATION deals with graphs, so we need to reconcile a data table and a graph. It shouldn't be too hard to notice (especially given the column names) that a row of data in the dataframe represents a transaction: the source node has the \"from\" attributes, the destination node has the \"to\" attributes, and the transaction has the dtg attribute. The first row therefore represents a connection from `abc@example1.com` with country value `Brazil` to `def@example2.com` with country value `India`. The last row represents a node that is not connected to any other node.\n",
    "\n",
    "Let's massage the data to something that CONSTELLATION likes. All of the addresses are email addresses, which CONSTELLATION should be clever enough to recognise, but we'd prefer to be explicit, so let's add the types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.from_address = df.from_address + '<Email>'\n",
    "df.to_address = df.to_address + '<Email>'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes are clever enough to work on a column at a time; we don't have to do our own loops.\n",
    "\n",
    "Let's check the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns are of type ``object``, which in this case means \"string\". However, CONSTELLATION expects datetimes to actually be of ``datetime`` type; if we try and upload datetimes as strings, CONSTELLATION won't recognise them as datetimes.\n",
    "\n",
    "Not to worry: pandas can fix that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtg = pd.to_datetime(df.dtg)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datetimes look exactly the same, but notice that the ``Not a Number`` value in the last row has become a ``Not a Timestamp`` value. If we look at the data types again, we can see that the ``dtg`` values are now datetimes, not objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``datetime64[ns]`` type means that datetimes are stored as a 64-bit number representing a number of nanoseconds from a zero timestamp. Not that we care that much about the storage: the important thing is that ``dtg`` is now \n",
    "a datetime column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "CONSTELLATION recognises source, destination and transaction attributes by the prefixes of their names. It won't be too surprising to find out that the prefixes are ``source``, ``destination``, and ``transaction``, with a ``.`` separating the prefixes from the attribute names.\n",
    "\n",
    "Let's rename the columns to match what CONSTELLATION expects. (We didn't do this first because the column headers were valid Python identifiers, it was easier to type ``df.dtg`` than ``df['transaction.DateTime']``.)\n",
    "\n",
    "Note that we use the name ``Identifier`` for the values that uniquely identify a particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'from_address': 'source.Label',\n",
    "    'from_country': 'source.Geo.Country',\n",
    "    'to_address': 'destination.Label',\n",
    "    'to_country': 'destination.Geo.Country',\n",
    "    'dtg': 'transaction.DateTime'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataframe is ready to be sent to CONSTELLATION. We'll create a new graph (using the ``new_graph()`` method), and send the dataframe to CONSTELLATION using the ``put_dataframe()`` method.\n",
    "\n",
    "If you get a Python `ConnectionRefusedError` when you run this cell, you've probably forgotten to start the CONSTELLATION external scripting server in the Tools menu. If you start it now, you'll have to go back and re-execute the \"`cc = constellation_client.Constellation()`\" cell, then come back here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.new_graph()\n",
    "cc.put_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTELLATION creates a new graph, accepts the contents of the dataframe, applies the schema, and automatically arranges the graph. Finally, it resets the view so you can see the complete graph.\n",
    "\n",
    "In this simple case, it's easy to see that the first two rows of the dataframe are correctly represented as nodes with transactions between them. The third row of the dataframe does not have a destination, so there is no transaction.\n",
    "\n",
    "If you open the `Attribute Editor` view and select a transaction, you'll see that they have the correct ``DateTime`` values.\n",
    "\n",
    "Of course, we didn't have to create a new graph. In the same graph, let's add a new node with a transaction from an existing node (`ghi@example3.com`). We'll use another (pretend) CSV file and modify the dataframe as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = '''\n",
    "from_address,from_country,to_address,to_country,dtg\n",
    "ghi@example3.com,Zambia,mno@example3.com,Brazil,2017-01-02 01:22:33\n",
    "'''.strip()\n",
    "dfn = pd.read_csv(io.StringIO(csv_data))\n",
    "dfn.from_address = dfn.from_address + '<Email>'\n",
    "dfn.to_address = dfn.to_address + '<Email>'\n",
    "dfn.dtg = pd.to_datetime(dfn.dtg)\n",
    "dfn = dfn.rename(columns={\n",
    "    'from_address': 'source.Label',\n",
    "    'from_country': 'source.Geo.Country',\n",
    "    'to_address': 'destination.Label',\n",
    "    'to_country': 'destination.Geo.Country',\n",
    "    'dtg': 'transaction.DateTime'})\n",
    "cc.put_dataframe(dfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Getting Data from CONSTELLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the graph that we created in Part 1 to see what happens when we get data from CONSTELLATION. Make sure that the graph is still displayed in CONSTELLATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be more data there. Let's look at the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of columns: {len(df.columns)}')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added five columns in part 1, but we get 50+ columns back! (The number may vary depending on the version of CONSTELLATION and your default schema.) \n",
    "\n",
    "What's going on?\n",
    "\n",
    "Remember that CONSTELLATION will apply the graph's schema to your data, and do an arrangement. Those other columns are the result of applying the schema, or (in the case of the x, y, z columns) applying an arrangement. The columns are in the dataframe in no particular order.\n",
    "\n",
    "Let's have a look at the data types in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The various ``selected`` columns are bool (that is, ``true`` or ``false`` values): an element is either selected or not selected. The ``transaction.DateTime`` is a ``datetime64[ns]`` as expected. Everything else should be unsurprising. One thing to notice is that ``source.nradius`` may be an ``int64``, even though in CONSTELLATION it's a ``float``. This is because ``nradius`` usually has integer values (typically 1.0), so the dataframe will convert it to an ``int64``. This shouldn't be a problem for us; it's still a number. This can happen for any column that only has integral values.\n",
    "\n",
    "We can see what the CONSTELLATION types are using ``cc``'s type attribute: the ``Constellation`` instance will remember the types after each call to ``get_dataframe()``. (Usually you won't have to worry about these.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTELLATION types such ``boolean``, ``datetime``, ``float``, ``int``, ``string`` convert to their obvious types in a dataframe. Other types convert to reasonable string equivalents; for example, ``icon`` converts to a string containing the name of the icon.\n",
    "\n",
    "The ``color`` type converts to a ``[red, green, blue, alpha]`` list, where each value ranges from 0 to 1. Some people are more used to web colors (in the format #RRGGBB). The following function converts a color list to a web color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_web_color(color):\n",
    "    \"\"\"Convert an RGB tuple of 0..1 to a web color.\"\"\"\n",
    "    \n",
    "    return f'#{int(color[0]*255):02x}{int(color[1]*255):02x}{int(color[2]*255):02x}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['source.color'])\n",
    "print(df['source.color'].apply(to_web_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which allows us to display labels using their node's schema color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "for label,color in df[['source.Label', 'source.color']].values:\n",
    "    h = '<span style=\"color:{}\">{}</span>'.format(to_web_color(color), html.escape(label))\n",
    "    display(HTML(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph elements\n",
    "\n",
    "Calling ``get_dataframe()`` with no parameters gave us four rows representing the whole graph: one row for each transaction, and a row for the singleton node.\n",
    "\n",
    "Sometimes we don't want all of the graph. We can ask for just the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe(vx=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five rows, one for each node. Note that all of the columns use the ``source`` prefix.\n",
    "\n",
    "We can ask for just the transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe(tx=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three rows, one for each transaction. Note that transactions always include the source and destination nodes.\n",
    "\n",
    "Finally, you can get just the elements that are selected. Before you run the next cell, use your mouse to select two nodes in the current graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe(vx=True, selected=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two rows, one for each selected node. Select some different nodes and try again. (If you don't see any rows here, it's because you didn't select any nodes. Select a couple of nodes and run the cell again.)\n",
    "\n",
    "Generally, you'll probably want one of ``vx=True`` when you're looking at nodes, or ``tx=True`` when you're looking at transactions.\n",
    "\n",
    "Select a couple of transactions, then run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe(tx=True, selected=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you ask for transactions, you not only get the transaction data, but the data for the modes at each end of the transaction as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing attributes\n",
    "\n",
    "You generally don't want all of the attributes that CONSTELLATION knows about. For example, the x,y,z coordinates are rarely useful when you're analysing data. The ``get_dataframe()`` method allows you to specify only the attributes you want. Not only does this use less space in the dataframe, but particularly for larger graphs, it can greatly reduce the time taken to get the data from the graph into a dataframe.\n",
    "\n",
    "First we'll find out what graph, node, and transaction attributes exist. The `get_attributes()` method returns a dictionary mapping attribute names to their CONSTELLATION types. For consistency with the other method return values, the attribute names are prefixed with `graph.`, `source.`, and `transaction.`. (Attributes that start with `graph.` are attributes of the graph itself, such as the graph's background color. You can see these in the \"Graph\" section of the Attribute Editor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = cc.get_attributes()\n",
    "attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify just the attributes you want, pass a list of attribute names using the ``attrs`` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe(vx=True, attrs=['source.Identifier', 'source.Type'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the graph: nodes\n",
    "\n",
    "There is a special attribute for each element that isn't visible in CONSTELLATION: ``source.[id]``, ``destination.[id]``, and ``transaction.[id]``. These are unique identifiers for each element. These identifiers can change whenever a graph is modified, so they can't be relied on to track an element. However, they can be used to identify a unique element when you get a dataframe, modify a value, and send the dataframe back to CONSTELLATION.\n",
    "\n",
    "For example, suppose we want to make all nodes in the ``@example3.com`` domain larger, and color them blue. We need the ``Identifier`` attribute (for the domain name), the ``nradius`` attribute so we can modify it, and the ``source.[id]`` attribute to tell CONSTELLATION which nodes to modify. We don't need to get the color, because we don't care what it is before we change it. xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe(vx=True, attrs=['source.Identifier', 'source.nradius', 'source.[id]'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out the ``example3.com`` nodes and double their radii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = df[df['source.Identifier'].str.endswith('@example3.com')].copy()\n",
    "e3['source.nradius'] *= 2\n",
    "e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to send the ``source.Identifier`` column back to CONSTELLATION, so let's drop it. We'll also add the color column. (Fortunately, CONSTELLATION is quite forgiving about color values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = e3.drop('source.Identifier', axis=1)\n",
    "e3['source.color'] = 'blue'\n",
    "e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can send this dataframe to CONSTELLATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.put_dataframe(e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two ``example3.com`` nodes should be noticably larger. However, the colors didn't change. This is because one of the things that CONSTELLATION does for us is to apply the graph's schema whenever you call ``put_dataframe()``, so the color changes to blue, then is immediately overridden by the schema.\n",
    "\n",
    "Let's put the node sizes back to 1, and call ``put_dataframe()`` again, but this time tell CONSTELLATION not to apply the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3['source.nradius'] = 1\n",
    "cc.put_dataframe(e3, complete_with_schema=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better.\n",
    "\n",
    "Another thing that CONSTELLATION does for a ``put_dataframe()`` is a simple arrangement. If you want to create your own arrangement, you have to tell CONSTELLATION not to do this using the ``arrange`` parameter.\n",
    "\n",
    "Let's arrange the nodes in a circle, just like the built-in circle arrangement. (Actually, wih only five nodes, it's more of a pentagon.) We don't need to know anything about the nodes for this one, we just need to know they exist. In particular, we don't need to know their current x, y, and z positions; we'll just create new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_dataframe(vx=True, attrs=['source.[id]'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "import numpy as np\n",
    "df['source.x'] = n * np.sin(2*np.pi*(df.index/n))\n",
    "df['source.y'] = n * np.cos(2*np.pi*(df.index/n))\n",
    "df['source.z'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.put_dataframe(df, arrange='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empty string tells CONSTELLATION not to perform any arrangement. (You could put the name of any arrangement plugin there, but there are better ways of doing that.)\n",
    "\n",
    "Also note that the blue nodes aren't blue any more, because the schema was applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the graph: transactions\n",
    "\n",
    "The graph we created earlier has a problem: the transactions have the wrong type. More precisely, they don't have any type. Let's fix that. We'll get all of the transactions from the graph, give them a type, and update the graph.\n",
    "\n",
    "When you run this, the transactions will turn green, indicating that schema completion has happened. You can look at the Attribute Editor to see that the transactions types are now `Communication`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transactions from the graph.\n",
    "#\n",
    "tx_df = cc.get_dataframe(tx=True, attrs=['transaction.[id]'])\n",
    "display(tx_df)\n",
    "\n",
    "# Add the transaction type.\n",
    "#\n",
    "tx_df['transaction.Type'] = 'Communication'\n",
    "display(tx_df)\n",
    "\n",
    "# Update the graph.\n",
    "#\n",
    "cc.put_dataframe(tx_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the graph: custom attributes\n",
    "\n",
    "Sometimes we want to add attributes that aren't defined in the graph's schema. For example, let's add an attribute called ``Country.Chars`` that shows the number of characters in each node's country name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = cc.get_dataframe(vx=True, attrs=['source.[id]', 'source.Geo.Country'])\n",
    "\n",
    "c_df['source.Country.Chars'] = c_df['source.Geo.Country'].str.len()\n",
    "display(c_df)\n",
    "display(c_df.dtypes)\n",
    "\n",
    "cc.put_dataframe(c_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the Attribute Editor, you'll see the new node attribute ``Country.Chars``. However, if you right-click on the attribute and select ``Modify Attribute``, you'll see that the new attribute is a string, not an integer, even though the value is an integer in the dataframe. This is because CONSTELLATION assumes that everything it doesn't recognise is a string.\n",
    "\n",
    "We can fix this by suffixing a type indicator to the column name. Let's create a new attribute called ``Country.Length`` which we turn into an integer by adding ``<integer>`` to the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = cc.get_dataframe(vx=True, attrs=['source.[id]', 'source.Geo.Country'])\n",
    "\n",
    "c_df['source.Country.Length<integer>'] = c_df['source.Geo.Country'].str.len()\n",
    "display(c_df)\n",
    "\n",
    "cc.put_dataframe(c_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at ``Country.Length`` in the Attribute Editor, we can see that it is an integer. (Click on the Edit button to see the different dialog box.)\n",
    "\n",
    "Other useful types are ``float`` and ``datetime``. You can see the complete list of types by adding a custom attribute in the Attribute Editor and looking at the ``Attribute Type`` dropdown list.\n",
    "\n",
    "(Note that there is currently no way to delete attributes externally, so if you want to delete the ``Country.Chars`` attribute, you'll have to do it manually.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting nodes and vertices\n",
    "\n",
    "The special identifier ``[delete]`` lets you delete nodes and transactions from the graph. It doesn't matter what value is in the ``source.[delete]`` column - just the fact that the column is there is sufficient to delete the graph elements. This means that all of the elements in the dataframe will be deleted, so be careful..\n",
    "\n",
    "Let's delete all singleton nodes. These nodes have no transactions connected to them, so when we get a dataframe, the ``destination.[id]`` value will be ``NaN``.\n",
    "\n",
    "(If we get all nodes with ``vx=True``, we won't get any data about transactions. If we get all transactions with ``tx=True``, we won't get the singleton nodes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the graph. (Names are included so we can check that the dataframe matches the graph.)\n",
    "#\n",
    "df = cc.get_dataframe(attrs=['source.[id]', 'source.Identifier', 'destination.[id]', 'destination.Identifier'])\n",
    "display(df)\n",
    "\n",
    "# Keep the singleton rows (where the destination.[id] is null).\n",
    "#\n",
    "df = df[df['destination.[id]'].isnull()]\n",
    "display(df)\n",
    "\n",
    "# Create a new dataframe with a source.[id] column containing all of the values from the df source.[id] column,\n",
    "# and a source.[delete] column containing any non-null value\n",
    "#\n",
    "del_df = pd.DataFrame({'source.[id]': df['source.[id]'], 'source.[delete]': 0})\n",
    "display(del_df)\n",
    "\n",
    "# Delete the singletons.\n",
    "#\n",
    "cc.put_dataframe(del_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we can delete transactions. Let's delete all transactions originating from ``ghi`` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all transactions.\n",
    "# We don't need all of the attributes for the delete, but we'll get them to use below.\n",
    "#\n",
    "df = cc.get_dataframe(tx=True)\n",
    "display(df)\n",
    "\n",
    "# Keep the transactions originating from 'ghi'.\n",
    "#\n",
    "df = df[df['source.Identifier'].str.startswith('ghi@')]\n",
    "display(df)\n",
    "\n",
    "# Create a new dataframe containing the transaction ids in the original dataframe.\n",
    "# It doesn't matter what the value of 'transaction.[delete]' is,\n",
    "# but we have to give it something.\n",
    "#\n",
    "del_df = pd.DataFrame({'transaction.[id]': df['transaction.[id]'], 'transaction.[delete]': 0})\n",
    "display(del_df)\n",
    "\n",
    "# Delete the transactions.\n",
    "#\n",
    "cc.put_dataframe(del_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's add a transaction that is exactly the same as the original. Remember that we originally fetched all of the attributes, so this new transaction will have the same attribute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.put_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Graph Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as node and transaction attributes, we can also get graph attributes. (Graph attributes can be seen in CONSTELLATION's Attribute Editor, above the node and transaction attributes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cc.get_graph_attributes()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one set of graph attributes, so there is one row in the dataframe.\n",
    "\n",
    "Let's display the `Geo.Country` attribute in a small size above the nodes, and the country flag as a decorator on the top-right of the node icon.\n",
    "\n",
    "A node label is defined as *``attribute-name``*``;``*``color``*``;``*``size``*, with multiple labels separated by pipes \"|\".\n",
    "\n",
    "A decorator is defined as ``\"nw\";\"ne\";\"se\";\"sw\";`` where any of the direction ordinals may be blank.\n",
    "\n",
    "We don't care what the top labels and decorators are right now, so we'll just create a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Geo.Country;Orange;0.5'\n",
    "df = pd.DataFrame({'node_labels_top': [labels], 'decorators': [';\"Geo.Country\";;;']})\n",
    "cc.set_graph_attributes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You may have to zoom in to see the smaller labels.)\n",
    "\n",
    "To add a label on the bottom in addition to the default ``Label`` attribute, you have to specify both labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Type;Teal;0.5|Label;LightBlue;1'\n",
    "df = pd.DataFrame({'node_labels_bottom': [labels]})\n",
    "cc.set_graph_attributes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Types\n",
    "\n",
    "CONSTELLATION defines many types. Use the ``describe_type()`` method to get a description of a particular type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cc.describe_type('Communication')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Plugins\n",
    "\n",
    "You can call CONSTELLATION plugins from Python (if you know what they're called). Let's arrange the graph in trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.run_plugin('ArrangeInTrees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can't see all of the graph, reset the view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.run_plugin('ResetView')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call plugins with parameters (if you know what they are). For example, the ``AddCustomBlaze`` plugin accepts a node id to add a blaze to.\n",
    "\n",
    "Let's add a blaze to each ``example3.com`` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all nodes and their identifiers.\n",
    "#\n",
    "df = cc.get_dataframe(vx=True, attrs=['source.Identifier', 'source.[id]'])\n",
    "\n",
    "# Whioch nodes belong to the example3.com domain?\n",
    "#\n",
    "e3 = df[df['source.Identifier'].str.endswith('@example3.com')]\n",
    "\n",
    "# Add a blaze to those nodes.\n",
    "#\n",
    "cc.run_plugin('AddCustomBlaze', args={'BlazeUtilities.vertex_ids': list(e3['source.[id]'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be neat and tidy and remove them again. We can reuse the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.run_plugin('RemoveBlaze', args={'BlazeUtilities.vertex_ids': list(e3['source.[id]'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multichoice parameters\n",
    "While most parameter values are quite simple (strings, integers, etc), some are a little more complex to deal with, such as the multichoice parameter. In order to pass multichoice parameter values to a plugin, you need to know the possible choices, and you need to know how to select them. \n",
    "\n",
    "Let's use the <i>select top n</i> plugin as an example. The schema view tells us that this plugin has a multichoice parameter called <i>SelectTopNPlugin.type</i>.\n",
    "\n",
    "Looking in the Data Access View, the type options will vary depending on the value given to the <i>SelectTopN.type_category</i> parameter. For this example we we set the type category to \"Online Identifier\", which will result in the possible type options being:\n",
    "- Online Identifier \n",
    "- Email\n",
    "\n",
    "In order to use this parameter, we need to create a string containing all options by joining each option with '\\n'. We also need to select all the options we want by prefixing them with '`âœ“ `' (i.e. Unicode character U+2713 (CHECK MARK) followed by character U+0020 (SPACE)). \n",
    "\n",
    "This is obviously not an ideal system, but this is how multichoice parameters were implemented at a time when it wasn't expected that CONSTELLATION's internal workings would be exposed via scripting or a REST API.\n",
    "\n",
    "(This plugin won't do anything on this simple graph.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a node.\n",
    "#\n",
    "cc.run_plugin('SelectSources')\n",
    "\n",
    "# Run the \"select top n\" plugin with a custom multichoice parameter value.\n",
    "#\n",
    "CHECK = '\\u2713'\n",
    "\n",
    "options = ['Online Identifier', 'Communication', 'User Name']\n",
    "checked = ['Communication']\n",
    "parameters = {\n",
    "    'SelectTopNPlugin.mode': \"Node\",\n",
    "    'SelectTopNPlugin.type_category': 'Online Location',\n",
    "    'SelectTopNPlugin.type': '\\n'.join([f'{CHECK} {v}' if v in checked else v for v in options]),\n",
    "    'SelectTopNPlugin.limit': 2\n",
    "}\n",
    "\n",
    "cc.run_plugin('SelectTopN', args=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "So how do we know what plugins exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins = cc.list_plugins()\n",
    "sorted(plugins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, at the moment there is no way of using the REST API to find out what each plugin does or what parameters it takes. However, you can go the the Schema View in CONSTELLATION and look at the ``Plugins`` tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to find out what a particular plugin does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.describe_plugin('ARRANGEINGRIDGENERAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Data Access Plugins\n",
    "\n",
    "Data Access plugins in CONSTELLATION are like any other plugins; they just have a different user interface. This means that they can be called from an external scripting client just like any other plugin.\n",
    "\n",
    "One caveat is that many of these plugins use the global parameters (seen at the top of the Data Access View).\n",
    "\n",
    "- Query Name\n",
    "- Range\n",
    "\n",
    "Let's try running a data access plugin, although to avoid connectivity problems we'll use the <i>Test Parameters</i> plugin in the <strong>Developer</strong> category of the Data Access View. This plugin doesn't actually access any external data, but rather simply exists to test the mechanisms CONSTELLATION uses to build and use plugin parameters. The plugin has many parameters, but for this example we will focus on the following:\n",
    "\n",
    "- ``GlobalCoreParameters.query_name``: A string representing the name of the query.\n",
    "- ``GlobalCoreParameters.datetime_range``: The datetime range; see below.\n",
    "\n",
    "You might want to try running this plugin manually on an empty graph before running the code below. The plugin will create two connected nodes containing `Comment` attribute values reflecting the values specified by the plugin parameters. (You can see these in the Attribute Editor after you've run the cell.)\n",
    "\n",
    "Note that the global parameters and plugin-specific parameters are named so they can be differentiated.\n",
    "\n",
    "Run the plugin a few times, changing the parameters each time, to satisfy yourself that this is the case. After you've done that, let's try running it programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Display the results of the plugin.\"\"\"\n",
    "    df = cc.get_dataframe()\n",
    "    print('query_name     :', df.loc[0, 'source.Comment'])\n",
    "    print('datetime_range :', df.loc[0, 'destination.Comment'])\n",
    "    print('all_parameters :', df.loc[0, 'transaction.Comment'])\n",
    "\n",
    "# Set up a counter.\n",
    "#\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.new_graph()\n",
    "\n",
    "counter += 1\n",
    "parameters = {\n",
    "    'CoreGlobalParameters.query_name': f'Query {counter} from a REST client',\n",
    "    'CoreGlobalParameters.datetime_range': 'P1D',\n",
    "    'TestParametersPlugin.robot': 'Bender',\n",
    "    'TestParametersPlugin.planets': f'{CHECK} Venus\\n{CHECK} Mars'\n",
    "}\n",
    "\n",
    "cc.run_plugin('TestParameters', args=parameters)\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datetime range can be an explicit range, or a duration from the current time.\n",
    "\n",
    "### Datetime range\n",
    "\n",
    "A range is represented by two ISO 8601 datetime values separated by a semi-colon. This represents an explicit start and end point. Examples are:\n",
    "\n",
    "- ``2016-01-01T00:00:00Z;2016-12-31T23:59:59Z``\n",
    "- ``2017-06-01T12:00:00Z;2017-06-01T13:00:00Z``\n",
    "\n",
    "### Datetime duration\n",
    "\n",
    "A duration is represented by a single ISO 8601 duration. This is converted to an explicit datetime range when the query is run. Examples are:\n",
    "\n",
    "- ``P1D``: one day\n",
    "- ``P7D``: 7 days\n",
    "- ``P1M``: one month\n",
    "- ``P1Y``: one year\n",
    "- ``P1M7D``: one month and seven days\n",
    "\n",
    "Note that only years, months, and days are supported (so ``P1H`` for one hour is not a valid period, for example.) For durations other than those, use Python to determine an explicit range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try calling the plugin again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.new_graph()\n",
    "\n",
    "counter += 1\n",
    "\n",
    "parameters['CoreGlobalParameters.query_name'] = f'Query {counter} from a REST client'\n",
    "parameters['CoreGlobalParameters.datetime_range'] = '2017-07-01T00:21:15Z;2017-07-14T00:21:15Z'\n",
    "\n",
    "cc.run_plugin('TestParameters', args=parameters)\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something's wrong?\n",
    "Sometimes things don't work. Like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.run_plugin('seletall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not particularly helpful. Fortunately, when something goes wrong the Python client remembers the most recent response, so we can look at what the REST server is telling us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(cc.r.content.decode('latin1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you mean, \"No such plugin as\"... Oh, we missed a letter. Let's try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.run_plugin('selectall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Taking a Screenshot\n",
    "\n",
    "It can be useful to include a screenshot of the graph in a notebook. It's easy to get an image encoded as data representing a PNG file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = cc.get_graph_image()\n",
    "Image(buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the built-in notebook facilities to display the image (which is returned from CONSTELLATION as a sequence of bytes, the encoding of the image in PNG format).\n",
    "\n",
    "If another window overlaps CONSTELLATION's graph display, you might see that window in the image. One way of avoiding this is to resize the CONSTELLATION window slightly first. Another way is to add a sleep before the `get_graph_image()` call and click in the CONSTELLATION window to bring it to the top.\n",
    "\n",
    "We can also use PIL (the Python Image Library) to turn the bytes into an image and manipulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(io.BytesIO(buf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to resize the image to fit it into a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, max_size):\n",
    "    w0 = img.width\n",
    "    h0 = img.height\n",
    "    s = max(w0, h0)/max_size\n",
    "    w1 = int(w0//s)\n",
    "    h1 = int(h0//s)\n",
    "    print(f'Resizing from {w0}x{h0} to {w1}x{h1}')\n",
    "    \n",
    "    return img.resize((w1, h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = resize(img, 512)\n",
    "\n",
    "# PIL images know how to display themselves.\n",
    "#\n",
    "small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image can be saved to a file. You can either write the bytes directly (remember the bytes are already in PNG format), or save the PIL image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_constellation_graph.png', 'wb') as f:\n",
    "    f.write(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.save('my_small_constellation_graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL is fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small.filter(PIL.ImageFilter.EMBOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = small.width\n",
    "h = small.height\n",
    "small.crop((int(w*0.25), int(h*0.25), int(w*0.75), int(h*0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonts depend on the operating system.\n",
    "#\n",
    "if os.name=='nt':\n",
    "    font = PIL.ImageFont.truetype('calibri.ttf', 20)\n",
    "else:\n",
    "    font = PIL.ImageFont.truetype('Oxygen-Sans.ttf', 20)\n",
    "draw = PIL.ImageDraw.Draw(small)\n",
    "draw.text((0, 0), 'This is my graph, it is mine.', (255, 200, 40), font=font)\n",
    "small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Part 7: NetworkX\n",
    "\n",
    "NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
    "\n",
    "This notebook isn't going to teach you how to use NetworkX, but you can extract your CONSTELLATION graph into a NetworkX graph for further analysis.\n",
    "\n",
    "We'll start by getting a dataframe containing the graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.run_plugin('ArrangeInGridGeneral')\n",
    "df = cc.get_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``constellation_client`` library contains a function that converts a dataframe to a NetworkX graph. You can see the documentation for it using the notebook's built-in help mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constellation_client.nx_from_dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've looked at the help, close the help window and create a NetworkX graph from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = constellation_client.nx_from_dataframe(df)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a node and see that it has the expected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes(data=True)['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at an edge and see that it has the expected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(g.edges(data=True))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetworkX can draw its graphs using a plotting library called ``matplotlib``. We just need to tell ``matplotlib`` to draw in the notebook, and get the correct positions and colors from the node and edge attributes. (We can use a convenience function provided by ``constellation_client`` to get the positions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "\n",
    "pos = constellation_client.get_nx_pos(g)\n",
    "node_colors = [to_web_color(g.nodes[n]['color']) for n in g.nodes()]\n",
    "edge_colors = [to_web_color(g.edges[e]['color']) for e in g.edges()]\n",
    "\n",
    "nx.draw(g, pos=pos, node_color=node_colors, edge_color=edge_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
